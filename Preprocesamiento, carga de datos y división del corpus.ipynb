{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4e7b3c4",
   "metadata": {},
   "source": [
    "# **Final Practice — Clickbait Detection**\n",
    "\n",
    "## **Alberto — Preprocesamiento, Carga de Datos y División del Corpus**\n",
    "\n",
    "**Equipo:**  \n",
    "**Alumnos:** Celso Alberto Gallegos Sánchez,  \n",
    "Montero Marin Andrea Jaqueline,  \n",
    "Liceaga Cardoso Ángel David,  \n",
    "Ramírez Verde Enrique  \n",
    "**Materia:** Procesamiento de Lenguaje Natural  \n",
    "**Fecha:** Noviembre 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a0e1c1",
   "metadata": {},
   "source": [
    "### **1. Carga de datos**\n",
    "\n",
    "En esta celda se realiza la carga de los corpora necesarios para la tarea de detección de clickbait:\n",
    "\n",
    "- `TA1C_dataset_detection_train.csv`: corpus de entrenamiento original.\n",
    "- `TA1C_dataset_detection_test.csv`: corpus de prueba sobre el que se generarán predicciones al final del proyecto.\n",
    "\n",
    "Acciones principales:\n",
    "- Importar las librerías necesarias (`pandas`, `pathlib`).\n",
    "- Definir las rutas de los archivos.\n",
    "- Cargar los CSV en `DataFrame` de `pandas`.\n",
    "- Mostrar información básica de las dimensiones del corpus de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "492b3cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c645d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del corpus de entrenamiento (raw): (2800, 6)\n",
      "Tamaño del segundo corpus (dev/test) raw: (700, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Tweet Date</th>\n",
       "      <th>Media Name</th>\n",
       "      <th>Media Origin</th>\n",
       "      <th>Teaser Text</th>\n",
       "      <th>Tag Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1302968016477589504</td>\n",
       "      <td>07-09-2020</td>\n",
       "      <td>El País</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>#SegundaDivisión  | La fortaleza del ataque: R...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1296805148950515713</td>\n",
       "      <td>21-08-2020</td>\n",
       "      <td>El País</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>Jorge Lanata a los argentinos que se van a Uru...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1303065732884967426</td>\n",
       "      <td>07-09-2020</td>\n",
       "      <td>El País</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>Raffo: “Los montevideanos deben estar alerta p...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1302462441520074757</td>\n",
       "      <td>06-09-2020</td>\n",
       "      <td>El País</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>Ecos del universo: joven uruguayo desentraña (...</td>\n",
       "      <td>Clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1301763104435589120</td>\n",
       "      <td>04-09-2020</td>\n",
       "      <td>El País</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>Propuesta quinquenal de ANEP: aumento de 3,8% ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet ID  Tweet Date Media Name Media Origin  \\\n",
       "0  1302968016477589504  07-09-2020    El País      Uruguay   \n",
       "1  1296805148950515713  21-08-2020    El País      Uruguay   \n",
       "2  1303065732884967426  07-09-2020    El País      Uruguay   \n",
       "3  1302462441520074757  06-09-2020    El País      Uruguay   \n",
       "4  1301763104435589120  04-09-2020    El País      Uruguay   \n",
       "\n",
       "                                         Teaser Text  Tag Value  \n",
       "0  #SegundaDivisión  | La fortaleza del ataque: R...         No  \n",
       "1  Jorge Lanata a los argentinos que se van a Uru...         No  \n",
       "2  Raffo: “Los montevideanos deben estar alerta p...         No  \n",
       "3  Ecos del universo: joven uruguayo desentraña (...  Clickbait  \n",
       "4  Propuesta quinquenal de ANEP: aumento de 3,8% ...         No  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = Path(\n",
    "    r\"C:\\Users\\Miner\\OneDrive\\Documentos\\7to semestre\\Procesamiento de Lenguaje Natural\\Final practice - Clickbait detection\\Final-practice---Clickbait-detection\\Material de apoyo\"\n",
    ")\n",
    "\n",
    "# Rutas de los archivos\n",
    "train_path = DATA_DIR / \"TA1C_dataset_detection_train.csv\"\n",
    "test_path  = DATA_DIR / \"TA1C_dataset_detection_dev.csv\"   # usa 'dev' como segundo corpus\n",
    "\n",
    "# Carga de los corpora\n",
    "df_train_raw = pd.read_csv(train_path)\n",
    "df_test_raw  = pd.read_csv(test_path)\n",
    "\n",
    "print(\"Tamaño del corpus de entrenamiento (raw):\", df_train_raw.shape)\n",
    "print(\"Tamaño del segundo corpus (dev/test) raw:\", df_test_raw.shape)\n",
    "\n",
    "# Vista rápida de las primeras filas del train\n",
    "df_train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5b4828",
   "metadata": {},
   "source": [
    "### **2. Selección de columnas y preprocesamiento mínimo**\n",
    "\n",
    "En este paso se seleccionan únicamente las columnas relevantes para la tarea:\n",
    "\n",
    "- **`Teaser Text`** → variable de entrada (X).\n",
    "- **`Tag Value`** → etiqueta/clase objetivo (y).\n",
    "\n",
    "Acciones principales:\n",
    "- Filtrar el `DataFrame` de entrenamiento para quedarnos con estas columnas.\n",
    "- Eliminar filas con valores nulos en estas columnas (si existieran).\n",
    "- Normalizar ligeramente el texto (por ejemplo, eliminando espacios en blanco al inicio y al final).\n",
    "\n",
    "El resultado será un `DataFrame` limpio (`df_all`) listo para hacer la división en *train* y *dev*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82bfc64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del corpus de entrenamiento limpio: (2800, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teaser Text</th>\n",
       "      <th>Tag Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#SegundaDivisión  | La fortaleza del ataque: R...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jorge Lanata a los argentinos que se van a Uru...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Raffo: “Los montevideanos deben estar alerta p...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ecos del universo: joven uruguayo desentraña (...</td>\n",
       "      <td>Clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Propuesta quinquenal de ANEP: aumento de 3,8% ...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Teaser Text  Tag Value\n",
       "0  #SegundaDivisión  | La fortaleza del ataque: R...         No\n",
       "1  Jorge Lanata a los argentinos que se van a Uru...         No\n",
       "2  Raffo: “Los montevideanos deben estar alerta p...         No\n",
       "3  Ecos del universo: joven uruguayo desentraña (...  Clickbait\n",
       "4  Propuesta quinquenal de ANEP: aumento de 3,8% ...         No"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nombres de las columnas a utilizar\n",
    "feature_col = \"Teaser Text\"\n",
    "target_col  = \"Tag Value\"\n",
    "\n",
    "# Nos quedamos solo con las columnas relevantes del train\n",
    "df_all = df_train_raw[[feature_col, target_col]].copy()\n",
    "\n",
    "# Eliminamos filas con valores nulos en texto o etiqueta\n",
    "df_all = df_all.dropna(subset=[feature_col, target_col])\n",
    "\n",
    "print(\"Tamaño del corpus de entrenamiento limpio:\", df_all.shape)\n",
    "df_all.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37083e0",
   "metadata": {},
   "source": [
    "### **3. División del corpus en train/dev (75%–25%)**\n",
    "\n",
    "En esta celda se realiza la división del corpus de entrenamiento en dos subconjuntos:\n",
    "\n",
    "- **Train set (75%)**: usado para entrenar el modelo.\n",
    "- **Dev set (25%)**: usado para validación y ajuste de hiperparámetros.\n",
    "\n",
    "Parámetros solicitados:\n",
    "- `shuffle = True`  → mezclar las instancias antes de dividir.\n",
    "- `random_state = 0` → semilla fija para reproducibilidad.\n",
    "- `stratify = y` → mantener la misma proporción de clases en *train* y *dev*.\n",
    "\n",
    "Se generan:\n",
    "- `X_train`, `y_train`\n",
    "- `X_dev`, `y_dev`\n",
    "- `df_train` y `df_dev` como `DataFrame` finales con las columnas `Teaser Text` y `Tag Value`,\n",
    "  que servirán como **dataframes finales para el entrenamiento**.\n",
    "\n",
    "Opcionalmente, también se guardan en CSV los subconjuntos ya divididos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b44b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño df_train: (2100, 2)\n",
      "Tamaño df_dev:   (700, 2)\n",
      "\n",
      "Distribución de clases en df_train:\n",
      "Tag Value\n",
      "No           0.715238\n",
      "Clickbait    0.284762\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Distribución de clases en df_dev:\n",
      "Tag Value\n",
      "No           0.714286\n",
      "Clickbait    0.285714\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teaser Text</th>\n",
       "      <th>Tag Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La letra que ha dejado sin bote a Pablo Díaz e...</td>\n",
       "      <td>Clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sanidad revende 30.000 dosis de la vacuna cont...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Video. Putin presume nuevo armamento nuclear r...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Salvador Cienfuegos, el general que nadie se a...</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @QuePasaCL: Conocimiento mundial: ¿Cuál es ...</td>\n",
       "      <td>Clickbait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Teaser Text  Tag Value\n",
       "0  La letra que ha dejado sin bote a Pablo Díaz e...  Clickbait\n",
       "1  Sanidad revende 30.000 dosis de la vacuna cont...         No\n",
       "2  Video. Putin presume nuevo armamento nuclear r...         No\n",
       "3  Salvador Cienfuegos, el general que nadie se a...         No\n",
       "4  RT @QuePasaCL: Conocimiento mundial: ¿Cuál es ...  Clickbait"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variables de entrada (X) y salida (y)\n",
    "X = df_all[feature_col]\n",
    "y = df_all[target_col]\n",
    "\n",
    "# División estratificada 75% / 25%\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.25,\n",
    "    shuffle=True,\n",
    "    random_state=0,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Conjutos de datos finales mas faciles de manejar\n",
    "df_train = pd.DataFrame({\n",
    "    feature_col: X_train,\n",
    "    target_col: y_train\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "df_dev = pd.DataFrame({\n",
    "    feature_col: X_dev,\n",
    "    target_col: y_dev\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "print(\"Tamaño df_train:\", df_train.shape)\n",
    "print(\"Tamaño df_dev:  \", df_dev.shape)\n",
    "\n",
    "print(\"\\nDistribución de clases en df_train:\")\n",
    "print(df_train[target_col].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nDistribución de clases en df_dev:\")\n",
    "print(df_dev[target_col].value_counts(normalize=True))\n",
    "\n",
    "# Vista rápida\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54485f37",
   "metadata": {},
   "source": [
    "### **4. subconjuntos preprocesados**\n",
    "\n",
    "Usen estos David L subconjuntos ya\n",
    "preprocesados y divididos:\n",
    "\n",
    "- `TA1C_dataset_detection_train_split.csv` → contiene el conjunto de entrenamiento (75%).\n",
    "- `TA1C_dataset_detection_dev_split.csv` → contiene el conjunto de desarrollo (25%).\n",
    "\n",
    "Ambos incluyen únicamente las columnas `Teaser Text` y `Tag Value` y están listos para ser\n",
    "usados en la etapa de tokenización y entrenamiento del LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ec8fa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos guardados:\n",
      " - TA1C_dataset_detection_train_split.csv\n",
      " - TA1C_dataset_detection_dev_split.csv\n"
     ]
    }
   ],
   "source": [
    "df_train.to_csv(\"TA1C_dataset_detection_train_split.csv\", index=False)\n",
    "df_dev.to_csv(\"TA1C_dataset_detection_dev_split.csv\", index=False)\n",
    "\n",
    "print(\"Archivos guardados:\")\n",
    "print(\" - TA1C_dataset_detection_train_split.csv\")\n",
    "print(\" - TA1C_dataset_detection_dev_split.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
